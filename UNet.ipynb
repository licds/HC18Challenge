{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "acc0e133",
      "metadata": {
        "id": "acc0e133"
      },
      "source": [
        "# Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "613f8398",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "613f8398",
        "outputId": "c616ed36-634a-455d-ca89-c46b73379508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage import io, color #Scikit-Image\n",
        "from PIL import Image # Pillow\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch # Will work on using PyTorch here later\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW8HiL5Fk8XE",
        "outputId": "a73e4793-f89c-4c4f-86a0-614dab89df0a"
      },
      "id": "GW8HiL5Fk8XE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parent_folder = '/content/gdrive/MyDrive/HC18'\n",
        "data_folder = '/content/gdrive/MyDrive/HC18/data'"
      ],
      "metadata": {
        "id": "juzXSlWtlJuA"
      },
      "id": "juzXSlWtlJuA",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b3a05c7b",
      "metadata": {
        "id": "b3a05c7b"
      },
      "source": [
        "# Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "62b98d5a",
      "metadata": {
        "id": "62b98d5a"
      },
      "outputs": [],
      "source": [
        "class HC18(Dataset):\n",
        "    def __init__(self, train = True, transformX = None, transformY = None):\n",
        "        self.pixel_file = pd.read_csv(os.path.join(data_folder, 'training_set_pixel_size_and_HC.csv'))\n",
        "        self.transformX = transformX\n",
        "        self.transformY = transformY\n",
        "        self.train = train\n",
        "        self.train_data, self.validation_data = train_test_split(self.pixel_file, test_size = validation_set_size, random_state = 5)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.train_data)\n",
        "        return len(self.validation_data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            imx_name = os.path.join(data_folder, 'training_set', self.train_data.iloc[index, 0])\n",
        "            imy_name = os.path.join(data_folder, 'training_set', self.train_data.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "        else:\n",
        "            imx_name = os.path.join(data_folder, 'training_set', self.validation_data.iloc[index, 0])\n",
        "            imy_name = os.path.join(data_folder, 'training_set', self.validation_data.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "        imx = Image.open(imx_name)\n",
        "        imy = Image.open(imy_name).convert('L')\n",
        "        \n",
        "        ## tried some data augmentation techniques\n",
        "        if self.train:\n",
        "          # Random horizontal flipping\n",
        "          if random.random() > 0.5:\n",
        "              imx = TF.hflip(imx)\n",
        "              imy = TF.hflip(imy)\n",
        "\n",
        "          # Random vertical flipping\n",
        "          if random.random() > 0.5:\n",
        "              imx = TF.vflip(imx)\n",
        "              imy = TF.vflip(imy)\n",
        "\n",
        "          # Random rotation\n",
        "          if random.random() > 0.8:\n",
        "            angle = random.choice([-30, -90, -60, -45 -15, 0, 15, 30, 45, 60, 90])\n",
        "            imx = TF.rotate(imx, angle)\n",
        "            imy = TF.rotate(imy, angle)\n",
        "        \n",
        "        # We will use resize, tensorlize, and normalize in the following cell\n",
        "        if self.transformX :\n",
        "            imx = self.transformX(imx)\n",
        "            imy = self.transformY(imy)\n",
        "        \n",
        "        sample = {'image': imx, 'annotation': imy}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "54af2466",
      "metadata": {
        "id": "54af2466"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(parent_folder, 'train_data.pickle'), 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "with open(os.path.join(parent_folder, 'validation_data.pickle'), 'rb') as f:\n",
        "    validation_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "40487d07",
      "metadata": {
        "id": "40487d07"
      },
      "outputs": [],
      "source": [
        "# Dataloaders\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = 2)\n",
        "validation_loader = DataLoader(dataset = validation_data, batch_size = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb6fe4b",
      "metadata": {
        "id": "7eb6fe4b"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c5a9be50",
      "metadata": {
        "id": "c5a9be50"
      },
      "outputs": [],
      "source": [
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            #nn.Dropout2d(0.7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            #nn.Dropout2d(0.77),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2), \n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "        if bilinear: \n",
        "            self.up = nn.Upsample(\n",
        "                scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "96dc1d58",
      "metadata": {
        "id": "96dc1d58"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256, bilinear = False)\n",
        "        self.up2 = up(512, 128, bilinear = False)\n",
        "        self.up3 = up(256, 64, bilinear = False)\n",
        "        self.up4 = up(128, 64, bilinear = False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "        self.dropout = torch.nn.Dropout2d(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.dropout(x)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ec0bcc7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec0bcc7b",
        "outputId": "4664fcda-a828-447f-d0cb-a6feb591a2a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded to GPU\n"
          ]
        }
      ],
      "source": [
        "model = UNet(1, 1)\n",
        "model.to('cuda')\n",
        "print(\"Model Loaded to GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f087ee21",
      "metadata": {
        "id": "f087ee21"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9849b274",
      "metadata": {
        "id": "9849b274"
      },
      "outputs": [],
      "source": [
        "# calculates similarity index between predicted and actual segmentation\n",
        "def dice_index(y_pred, y_actual):\n",
        "    smooth = 0.000001\n",
        "    size_of_batch = y_pred.size(0)\n",
        "    \n",
        "    p1 = y_pred.view(size_of_batch, -1)\n",
        "    p2 = y_actual.view(size_of_batch, -1)\n",
        "    \n",
        "    intersection = (p1 * p2).sum()\n",
        "    \n",
        "    dice =  ((2.0 * intersection )+ smooth) / (p1.sum() + p2.sum() + smooth)\n",
        "    #dice.requires_grad = True\n",
        "    \n",
        "    return dice\n",
        "\n",
        "# calculate dice loss which will be later used in loss function calculation\n",
        "def dice_loss(y_predict, y_train): ## to add in bce looss\n",
        "    return 1 -(dice_index(y_predict, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only train the model if you want to retrain, screw down to load the pre-trained model"
      ],
      "metadata": {
        "id": "XgoCW9sDpT6s"
      },
      "id": "XgoCW9sDpT6s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3526d833",
      "metadata": {
        "scrolled": false,
        "id": "3526d833",
        "outputId": "a65b08c3-9fb2-4179-9972-b32ae3830a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  1 Batch:  0 Current Loss:  0.6433738470077515\n",
            "Epoch:  1 Batch:  50 Current Loss:  0.4641196131706238\n",
            "Epoch:  1 Batch:  100 Current Loss:  0.380474328994751\n",
            "Epoch:  1 Batch:  150 Current Loss:  0.4855611324310303\n",
            "Epoch:  1 Batch:  200 Current Loss:  0.23920778930187225\n",
            "Epoch:  1 Batch:  250 Current Loss:  0.2878831923007965\n",
            "Epoch:  1 Batch:  300 Current Loss:  0.2290586233139038\n",
            "Epoch:  1 Batch:  350 Current Loss:  0.2021007090806961\n",
            "================================================================================\n",
            "Epoch 1 completed\n",
            "Average train loss is 0.3392075290158391: \n",
            "Average validation loss is 0.23661553367972374\n",
            "================================================================================\n",
            "Epoch:  2 Batch:  0 Current Loss:  0.4294271469116211\n",
            "Epoch:  2 Batch:  50 Current Loss:  0.3727321922779083\n",
            "Epoch:  2 Batch:  100 Current Loss:  0.177557572722435\n",
            "Epoch:  2 Batch:  150 Current Loss:  0.3599812984466553\n",
            "Epoch:  2 Batch:  200 Current Loss:  0.15867923200130463\n",
            "Epoch:  2 Batch:  250 Current Loss:  0.22639372944831848\n",
            "Epoch:  2 Batch:  300 Current Loss:  0.16440246999263763\n",
            "Epoch:  2 Batch:  350 Current Loss:  0.16935789585113525\n",
            "================================================================================\n",
            "Epoch 2 completed\n",
            "Average train loss is 0.2435729724727571: \n",
            "Average validation loss is 0.19405696973204611\n",
            "================================================================================\n",
            "Epoch:  3 Batch:  0 Current Loss:  0.3165295124053955\n",
            "Epoch:  3 Batch:  50 Current Loss:  0.22944790124893188\n",
            "Epoch:  3 Batch:  100 Current Loss:  0.11709217727184296\n",
            "Epoch:  3 Batch:  150 Current Loss:  0.2869001626968384\n",
            "Epoch:  3 Batch:  200 Current Loss:  0.10663533210754395\n",
            "Epoch:  3 Batch:  250 Current Loss:  0.19217213988304138\n",
            "Epoch:  3 Batch:  300 Current Loss:  0.11061668395996094\n",
            "Epoch:  3 Batch:  350 Current Loss:  0.12727974355220795\n",
            "================================================================================\n",
            "Epoch 3 completed\n",
            "Average train loss is 0.18675202332437038: \n",
            "Average validation loss is 0.13274467132985593\n",
            "================================================================================\n",
            "Epoch:  4 Batch:  0 Current Loss:  0.23804005980491638\n",
            "Epoch:  4 Batch:  50 Current Loss:  0.19460181891918182\n",
            "Epoch:  4 Batch:  100 Current Loss:  0.09767650067806244\n",
            "Epoch:  4 Batch:  150 Current Loss:  0.26289430260658264\n",
            "Epoch:  4 Batch:  200 Current Loss:  0.0763000100851059\n",
            "Epoch:  4 Batch:  250 Current Loss:  0.1296159029006958\n",
            "Epoch:  4 Batch:  300 Current Loss:  0.13205841183662415\n",
            "Epoch:  4 Batch:  350 Current Loss:  0.1053936555981636\n",
            "================================================================================\n",
            "Epoch 4 completed\n",
            "Average train loss is 0.14921019861474633: \n",
            "Average validation loss is 0.11514420188963413\n",
            "================================================================================\n",
            "Epoch:  5 Batch:  0 Current Loss:  0.2318965643644333\n",
            "Epoch:  5 Batch:  50 Current Loss:  0.17797839641571045\n",
            "Epoch:  5 Batch:  100 Current Loss:  0.1066666841506958\n",
            "Epoch:  5 Batch:  150 Current Loss:  0.2479076087474823\n",
            "Epoch:  5 Batch:  200 Current Loss:  0.06514342874288559\n",
            "Epoch:  5 Batch:  250 Current Loss:  0.11952345073223114\n",
            "Epoch:  5 Batch:  300 Current Loss:  0.09405821561813354\n",
            "Epoch:  5 Batch:  350 Current Loss:  0.09749320149421692\n",
            "================================================================================\n",
            "Epoch 5 completed\n",
            "Average train loss is 0.129357021311298: \n",
            "Average validation loss is 0.09888818223029375\n",
            "================================================================================\n",
            "Epoch:  6 Batch:  0 Current Loss:  0.19518697261810303\n",
            "Epoch:  6 Batch:  50 Current Loss:  0.16516853868961334\n",
            "Epoch:  6 Batch:  100 Current Loss:  0.052796363830566406\n",
            "Epoch:  6 Batch:  150 Current Loss:  0.23411032557487488\n",
            "Epoch:  6 Batch:  200 Current Loss:  0.054239653050899506\n",
            "Epoch:  6 Batch:  250 Current Loss:  0.10605718195438385\n",
            "Epoch:  6 Batch:  300 Current Loss:  0.0891859158873558\n",
            "Epoch:  6 Batch:  350 Current Loss:  0.10737640410661697\n",
            "================================================================================\n",
            "Epoch 6 completed\n",
            "Average train loss is 0.11911226535215974: \n",
            "Average validation loss is 0.12351634500548243\n",
            "================================================================================\n",
            "Epoch:  7 Batch:  0 Current Loss:  0.18028557300567627\n",
            "Epoch:  7 Batch:  50 Current Loss:  0.10142526775598526\n",
            "Epoch:  7 Batch:  100 Current Loss:  0.09312376379966736\n",
            "Epoch:  7 Batch:  150 Current Loss:  0.31604671478271484\n",
            "Epoch:  7 Batch:  200 Current Loss:  0.05416463315486908\n",
            "Epoch:  7 Batch:  250 Current Loss:  0.11526858806610107\n",
            "Epoch:  7 Batch:  300 Current Loss:  0.07285336405038834\n",
            "Epoch:  7 Batch:  350 Current Loss:  0.07563678175210953\n",
            "================================================================================\n",
            "Epoch 7 completed\n",
            "Average train loss is 0.11010538708418607: \n",
            "Average validation loss is 0.1031508806720376\n",
            "================================================================================\n",
            "Epoch:  8 Batch:  0 Current Loss:  0.2212897092103958\n",
            "Epoch:  8 Batch:  50 Current Loss:  0.1934771090745926\n",
            "Epoch:  8 Batch:  100 Current Loss:  0.09084123373031616\n",
            "Epoch:  8 Batch:  150 Current Loss:  0.16402094066143036\n",
            "Epoch:  8 Batch:  200 Current Loss:  0.053031422197818756\n",
            "Epoch:  8 Batch:  250 Current Loss:  0.10984241217374802\n",
            "Epoch:  8 Batch:  300 Current Loss:  0.09246563911437988\n",
            "Epoch:  8 Batch:  350 Current Loss:  0.0807175561785698\n",
            "================================================================================\n",
            "Epoch 8 completed\n",
            "Average train loss is 0.09838247039355337: \n",
            "Average validation loss is 0.10894602594897151\n",
            "================================================================================\n",
            "Epoch:  9 Batch:  0 Current Loss:  0.19156892597675323\n",
            "Epoch:  9 Batch:  50 Current Loss:  0.12949106097221375\n",
            "Epoch:  9 Batch:  100 Current Loss:  0.049674391746520996\n",
            "Epoch:  9 Batch:  150 Current Loss:  0.19694364070892334\n",
            "Epoch:  9 Batch:  200 Current Loss:  0.04998950660228729\n",
            "Epoch:  9 Batch:  250 Current Loss:  0.09127423912286758\n",
            "Epoch:  9 Batch:  300 Current Loss:  0.09061872959136963\n",
            "Epoch:  9 Batch:  350 Current Loss:  0.12399175763130188\n",
            "================================================================================\n",
            "Epoch 9 completed\n",
            "Average train loss is 0.09535121824592352: \n",
            "Average validation loss is 0.08928960274904967\n",
            "================================================================================\n",
            "Epoch:  10 Batch:  0 Current Loss:  0.14874723553657532\n",
            "Epoch:  10 Batch:  50 Current Loss:  0.14207305014133453\n",
            "Epoch:  10 Batch:  100 Current Loss:  0.06024578958749771\n",
            "Epoch:  10 Batch:  150 Current Loss:  0.21529601514339447\n",
            "Epoch:  10 Batch:  200 Current Loss:  0.055037178099155426\n",
            "Epoch:  10 Batch:  250 Current Loss:  0.08707495033740997\n",
            "Epoch:  10 Batch:  300 Current Loss:  0.11142372339963913\n",
            "Epoch:  10 Batch:  350 Current Loss:  0.06615769863128662\n",
            "================================================================================\n",
            "Epoch 10 completed\n",
            "Average train loss is 0.0894187081605196: \n",
            "Average validation loss is 0.0978454232774675\n",
            "================================================================================\n",
            "Epoch:  11 Batch:  0 Current Loss:  0.16512919962406158\n",
            "Epoch:  11 Batch:  50 Current Loss:  0.08921182155609131\n",
            "Epoch:  11 Batch:  100 Current Loss:  0.04986029490828514\n",
            "Epoch:  11 Batch:  150 Current Loss:  0.16824084520339966\n",
            "Epoch:  11 Batch:  200 Current Loss:  0.056791409850120544\n",
            "Epoch:  11 Batch:  250 Current Loss:  0.08116737753152847\n",
            "Epoch:  11 Batch:  300 Current Loss:  0.0663892924785614\n",
            "Epoch:  11 Batch:  350 Current Loss:  0.11872529983520508\n",
            "================================================================================\n",
            "Epoch 11 completed\n",
            "Average train loss is 0.08311393772251904: \n",
            "Average validation loss is 0.15636542132124304\n",
            "================================================================================\n",
            "Epoch:  12 Batch:  0 Current Loss:  0.11300377547740936\n",
            "Epoch:  12 Batch:  50 Current Loss:  0.08032263815402985\n",
            "Epoch:  12 Batch:  100 Current Loss:  0.046476688235998154\n",
            "Epoch:  12 Batch:  150 Current Loss:  0.11076280474662781\n",
            "Epoch:  12 Batch:  200 Current Loss:  0.043368205428123474\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  12 Batch:  250 Current Loss:  0.07660360634326935\n",
            "Epoch:  12 Batch:  300 Current Loss:  0.0519089512526989\n",
            "Epoch:  12 Batch:  350 Current Loss:  0.0540185309946537\n",
            "================================================================================\n",
            "Epoch 12 completed\n",
            "Average train loss is 0.08360550140962004: \n",
            "Average validation loss is 0.13781525341793896\n",
            "================================================================================\n",
            "Epoch:  13 Batch:  0 Current Loss:  0.15992102026939392\n",
            "Epoch:  13 Batch:  50 Current Loss:  0.09184205532073975\n",
            "Epoch:  13 Batch:  100 Current Loss:  0.04061045125126839\n",
            "Epoch:  13 Batch:  150 Current Loss:  0.06440312415361404\n",
            "Epoch:  13 Batch:  200 Current Loss:  0.04923461377620697\n",
            "Epoch:  13 Batch:  250 Current Loss:  0.09414017200469971\n",
            "Epoch:  13 Batch:  300 Current Loss:  0.05911192670464516\n",
            "Epoch:  13 Batch:  350 Current Loss:  0.052150193601846695\n",
            "================================================================================\n",
            "Epoch 13 completed\n",
            "Average train loss is 0.07796593022998423: \n",
            "Average validation loss is 0.0820119304023683\n",
            "================================================================================\n",
            "Epoch:  14 Batch:  0 Current Loss:  0.12364372611045837\n",
            "Epoch:  14 Batch:  50 Current Loss:  0.07903099060058594\n",
            "Epoch:  14 Batch:  100 Current Loss:  0.03264808654785156\n",
            "Epoch:  14 Batch:  150 Current Loss:  0.14662036299705505\n",
            "Epoch:  14 Batch:  200 Current Loss:  0.05296368896961212\n",
            "Epoch:  14 Batch:  250 Current Loss:  0.08107280731201172\n",
            "Epoch:  14 Batch:  300 Current Loss:  0.06185009703040123\n",
            "Epoch:  14 Batch:  350 Current Loss:  0.06289736181497574\n",
            "================================================================================\n",
            "Epoch 14 completed\n",
            "Average train loss is 0.07631639972794801: \n",
            "Average validation loss is 0.07819252043962478\n",
            "================================================================================\n",
            "Epoch:  15 Batch:  0 Current Loss:  0.1419375240802765\n",
            "Epoch:  15 Batch:  50 Current Loss:  0.08953934907913208\n",
            "Epoch:  15 Batch:  100 Current Loss:  0.03223104029893875\n",
            "Epoch:  15 Batch:  150 Current Loss:  0.10324817895889282\n",
            "Epoch:  15 Batch:  200 Current Loss:  0.042779482901096344\n",
            "Epoch:  15 Batch:  250 Current Loss:  0.08131673187017441\n",
            "Epoch:  15 Batch:  300 Current Loss:  0.06921886652708054\n",
            "Epoch:  15 Batch:  350 Current Loss:  0.07630111277103424\n",
            "================================================================================\n",
            "Epoch 15 completed\n",
            "Average train loss is 0.07516385571565479: \n",
            "Average validation loss is 0.12385160321369768\n",
            "================================================================================\n",
            "Epoch:  16 Batch:  0 Current Loss:  0.09789159893989563\n",
            "Epoch:  16 Batch:  50 Current Loss:  0.08736562728881836\n",
            "Epoch:  16 Batch:  100 Current Loss:  0.03615609183907509\n",
            "Epoch:  16 Batch:  150 Current Loss:  0.06473787873983383\n",
            "Epoch:  16 Batch:  200 Current Loss:  0.056529827415943146\n",
            "Epoch:  16 Batch:  250 Current Loss:  0.07161562889814377\n",
            "Epoch:  16 Batch:  300 Current Loss:  0.06801199167966843\n",
            "Epoch:  16 Batch:  350 Current Loss:  0.0936279147863388\n",
            "================================================================================\n",
            "Epoch 16 completed\n",
            "Average train loss is 0.07492430400568992: \n",
            "Average validation loss is 0.07087645823135973\n",
            "================================================================================\n",
            "Epoch:  17 Batch:  0 Current Loss:  0.11648746579885483\n",
            "Epoch:  17 Batch:  50 Current Loss:  0.06676964461803436\n",
            "Epoch:  17 Batch:  100 Current Loss:  0.030339285731315613\n",
            "Epoch:  17 Batch:  150 Current Loss:  0.08571642637252808\n",
            "Epoch:  17 Batch:  200 Current Loss:  0.04695247486233711\n",
            "Epoch:  17 Batch:  250 Current Loss:  0.07875658571720123\n",
            "Epoch:  17 Batch:  300 Current Loss:  0.05939337611198425\n",
            "Epoch:  17 Batch:  350 Current Loss:  0.07243186235427856\n",
            "================================================================================\n",
            "Epoch 17 completed\n",
            "Average train loss is 0.0707272329973057: \n",
            "Average validation loss is 0.09880854098126292\n",
            "================================================================================\n",
            "Epoch:  18 Batch:  0 Current Loss:  0.10730977356433868\n",
            "Epoch:  18 Batch:  50 Current Loss:  0.05996209755539894\n",
            "Epoch:  18 Batch:  100 Current Loss:  0.04026859626173973\n",
            "Epoch:  18 Batch:  150 Current Loss:  0.08890987932682037\n",
            "Epoch:  18 Batch:  200 Current Loss:  0.046586960554122925\n",
            "Epoch:  18 Batch:  250 Current Loss:  0.08430758863687515\n",
            "Epoch:  18 Batch:  300 Current Loss:  0.046370431780815125\n",
            "Epoch:  18 Batch:  350 Current Loss:  0.11341641843318939\n",
            "================================================================================\n",
            "Epoch 18 completed\n",
            "Average train loss is 0.07089849851559847: \n",
            "Average validation loss is 0.10855008497834205\n",
            "================================================================================\n",
            "Epoch:  19 Batch:  0 Current Loss:  0.12352075427770615\n",
            "Epoch:  19 Batch:  50 Current Loss:  0.05829460546374321\n",
            "Epoch:  19 Batch:  100 Current Loss:  0.03955719619989395\n",
            "Epoch:  19 Batch:  150 Current Loss:  0.10418285429477692\n",
            "Epoch:  19 Batch:  200 Current Loss:  0.044513944536447525\n",
            "Epoch:  19 Batch:  250 Current Loss:  0.0912691056728363\n",
            "Epoch:  19 Batch:  300 Current Loss:  0.07652262598276138\n",
            "Epoch:  19 Batch:  350 Current Loss:  0.06836268305778503\n",
            "================================================================================\n",
            "Epoch 19 completed\n",
            "Average train loss is 0.06732339656446129: \n",
            "Average validation loss is 0.09892001233994961\n",
            "================================================================================\n",
            "Epoch:  20 Batch:  0 Current Loss:  0.12181481719017029\n",
            "Epoch:  20 Batch:  50 Current Loss:  0.04945629462599754\n",
            "Epoch:  20 Batch:  100 Current Loss:  0.03530599921941757\n",
            "Epoch:  20 Batch:  150 Current Loss:  0.07058294862508774\n",
            "Epoch:  20 Batch:  200 Current Loss:  0.042521264404058456\n",
            "Epoch:  20 Batch:  250 Current Loss:  0.07105398923158646\n",
            "Epoch:  20 Batch:  300 Current Loss:  0.04082939028739929\n",
            "Epoch:  20 Batch:  350 Current Loss:  0.07437941431999207\n",
            "================================================================================\n",
            "Epoch 20 completed\n",
            "Average train loss is 0.06650461064651608: \n",
            "Average validation loss is 0.1435752903111279\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "epochs = 20 \n",
        "\n",
        "train_running_loss_history = []\n",
        "validation_running_loss_history =[]\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_running_loss = 0.0\n",
        "    validation_running_loss = 0.0  \n",
        "    model.train()\n",
        "    for ith_batch, sample_batched in enumerate(train_loader):\n",
        "        X_train = sample_batched['image'].cuda()\n",
        "        y_train = sample_batched['annotation'].to(\"cuda:0\")\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train)\n",
        "        loss = 0.30 * dice_loss(y_pred, y_train) +  0.70 * criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ith_batch % 50 == 0:\n",
        "            print('Epoch: ', e + 1, 'Batch: ', ith_batch, 'Current Loss: ', loss.item())\n",
        "        train_running_loss += loss.item()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for ith_batch, sample_batched in enumerate(validation_loader):\n",
        "                X_val = sample_batched['image'].cuda()\n",
        "                y_val = sample_batched['annotation'].to(\"cuda:0\")\n",
        "                y_out = model(X_val)\n",
        "                out_val = (y_out + 0.5).int().float()\n",
        "                val_loss = 0.3 * dice_loss(out_val, y_val)  + 0.7 * criterion(y_out, y_val)\n",
        "                validation_running_loss += val_loss.item()\n",
        "            print(\"================================================================================\")\n",
        "            print(\"Epoch {} completed\".format(e + 1))\n",
        "\n",
        "            train_epoch_loss = train_running_loss / len(train_loader)\n",
        "            validation_epoch_loss = validation_running_loss / len(validation_loader)\n",
        "\n",
        "            print(\"Average train loss is {}: \".format(train_epoch_loss))\n",
        "            print(\"Average validation loss is {}\".format(validation_epoch_loss))\n",
        "            print(\"================================================================================\")\n",
        "            train_running_loss_history.append(train_epoch_loss)\n",
        "            validation_running_loss_history.append(validation_epoch_loss)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e50f178",
      "metadata": {
        "id": "5e50f178",
        "outputId": "d5104076-c3cf-4317-aeac-18929bd04252"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x15541f897b80>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_running_loss_history, label = 'Train Loss')\n",
        "plt.plot(validation_running_loss_history, label = 'Validation Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf76e565",
      "metadata": {
        "id": "bf76e565",
        "outputId": "8b859dd5-0b03-449d-c089-99fc2c91638c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 572, 572])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "X_train.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae1523f",
      "metadata": {
        "id": "8ae1523f"
      },
      "outputs": [],
      "source": [
        "torch.save(model, os.path.join(parent_folder, 'savedmodel/UNet.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can load a model instead"
      ],
      "metadata": {
        "id": "AuyGNAKgpeUl"
      },
      "id": "AuyGNAKgpeUl"
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(os.path.join(parent_folder, 'savedmodel/UNet.pt'))\n",
        "model.to('cuda')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDtDGhjVnHvP",
        "outputId": "d512de0c-abb7-4eb0-db50-6fb618923f4c"
      },
      "id": "sDtDGhjVnHvP",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): inconv(\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down1): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down4): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up1): up(\n",
              "    (up): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2): up(\n",
              "    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3): up(\n",
              "    (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4): up(\n",
              "    (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): outconv(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "abe50d1b",
      "metadata": {
        "id": "abe50d1b"
      },
      "outputs": [],
      "source": [
        "def avg_dice_index(dataloader):\n",
        "    dice = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for ith_batch, sample_batched in enumerate(dataloader):\n",
        "            X_train = sample_batched['image'].to('cuda')\n",
        "            y_train = sample_batched['annotation'].to('cuda')\n",
        "            y_predict = (model(X_train) + 0.5).int().float()\n",
        "            dice += dice_index(y_predict, y_train)\n",
        "    avg_dice = dice / len(dataloader)\n",
        "    return avg_dice.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4558cda4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4558cda4",
        "outputId": "3a34f8e4-4871-4d0a-c734-aa11d66f12d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9150426387786865"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "avg_dice_index(validation_loader)    #### Dice index of validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "175c35d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "175c35d2",
        "outputId": "ca022514-5909-4b75-b855-8b18fc714c0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9025920629501343"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "avg_dice_index(train_loader)    #### Dice index of train data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}