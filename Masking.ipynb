{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f703ec85",
      "metadata": {
        "id": "f703ec85"
      },
      "source": [
        "## Download Data \n",
        "Download data from https://zenodo.org/record/1327317#.Y1Fs1uzMI1I\n",
        "<br>Do not upload them to github, the gitignore file will ignore all .zip files.\n",
        "\n",
        "<br>Run the following cells to unzip the files.\n",
        "<br>Do not upload images to github, the gitignore file will ignore all .png files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85825cce",
      "metadata": {
        "id": "85825cce"
      },
      "outputs": [],
      "source": [
        "!unzip training_set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f49d121",
      "metadata": {
        "id": "3f49d121"
      },
      "outputs": [],
      "source": [
        "!unzip test_set.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04b223cf",
      "metadata": {
        "id": "04b223cf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "250b4627",
      "metadata": {
        "id": "250b4627"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7f8d469",
      "metadata": {
        "id": "d7f8d469"
      },
      "source": [
        "### Warning!!!\n",
        "Run the following cell ONLY once. If you have ran this part before, even if the jupyter notebook lost connection, do not run it again. The images you downloaded have been modified with the masks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "Sk5r5WSo5Cg0"
      },
      "id": "Sk5r5WSo5Cg0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_folder = '/content/gdrive/MyDrive/HC18'\n",
        "data_folder = '/content/gdrive/MyDrive/HC18/data'"
      ],
      "metadata": {
        "id": "qsBcRr6z47Nk"
      },
      "id": "qsBcRr6z47Nk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d07544cb",
      "metadata": {
        "id": "d07544cb"
      },
      "outputs": [],
      "source": [
        "train_pixel_file = pd.read_csv(os.path.join(data_folder, 'training_set_pixel_size_and_HC.csv'))\n",
        "train_pixel_file.head()\n",
        "# This Dataframe will be used to extract image names hence by doing image_name + '_Annotation' \n",
        "# we will get annotation names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63c9e74",
      "metadata": {
        "id": "d63c9e74"
      },
      "source": [
        "<table align=\"left\"><tr>\n",
        "<td> \n",
        "  <p align=\"center\" style=\"padding: 10px\">\n",
        "    <img alt=\"Forwarding\" src=\"training_set/000_HC.png\" width=\"320\">\n",
        "    <br>\n",
        "    <em style=\"color: grey\">Original Image 000_HC.png</em>\n",
        "  </p> \n",
        "</td>\n",
        "<td> \n",
        "  <p align=\"center\">\n",
        "    <img alt=\"Routing\" src=\"training_set/000_HC_Annotation.png\" width=\"320\">\n",
        "    <br>\n",
        "    <em style=\"color: grey\">Annotation of Image 000_HC_Annotation.png</em>\n",
        "  </p> \n",
        "</td>\n",
        "</tr></table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa1ae435",
      "metadata": {
        "id": "fa1ae435"
      },
      "outputs": [],
      "source": [
        "# This function takes the annotation of image and spits out corresponding mask\n",
        "def masking(image):\n",
        "    # Convert image to grayscale\n",
        "    imgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(imgray, 127, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    ellipse = cv2.fitEllipse(contours[0])\n",
        "    return cv2.ellipse(image, ellipse, (255,255,255), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ead49f0",
      "metadata": {
        "id": "4ead49f0"
      },
      "source": [
        "### This is something your will get running the following code\n",
        "<br>\n",
        "<div>\n",
        "    <img src=\"attachment:Screen%20Shot%202022-10-20%20at%201.16.47%20PM.png\" width=\"900\" align=\"left\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054229aa",
      "metadata": {
        "id": "054229aa"
      },
      "outputs": [],
      "source": [
        "# Check if our masking function is working correctly\n",
        "fig = plt.figure(figsize = (30,7))\n",
        "for index in range(5):\n",
        "  file_path = os.path.join('training_set', train_pixel_file.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "  #print(file_path)\n",
        "  ax = fig.add_subplot(2, 7, index+1)             ## annoted plot\n",
        "  plt.imshow(cv2.imread(file_path))\n",
        "    \n",
        "  ax = fig.add_subplot(2, 7, index+8)\n",
        "  plt.imshow(masking(cv2.imread(file_path)))        ## mask plot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b656d1a5",
      "metadata": {
        "id": "b656d1a5"
      },
      "source": [
        "Do not proceed until you get the right masks for the first five annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4753d15f",
      "metadata": {
        "id": "4753d15f"
      },
      "outputs": [],
      "source": [
        "# Here we loop through training set and  take annotations one by one and REPLACE them with corresponding masks\n",
        "for index in range(len(train_pixel_file)):\n",
        "    file_path = os.path.join(data_folder,'training_set', train_pixel_file.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "    image = cv2.imread(file_path)\n",
        "    mask = masking(image)\n",
        "    cv2.imwrite(file_path, mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732cd82a",
      "metadata": {
        "id": "732cd82a"
      },
      "source": [
        "### Warning!!!\n",
        "Do not run the above code again! The images you downloaded have been modified with the masks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}