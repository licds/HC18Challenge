{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "acc0e133",
      "metadata": {
        "id": "acc0e133"
      },
      "source": [
        "# Libraries Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "613f8398",
      "metadata": {
        "id": "613f8398",
        "outputId": "682bb2c9-c9d6-4c19-ce38-8d4240acb6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.0+cu117\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage import io, color #Scikit-Image\n",
        "from PIL import Image # Pillow\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch # Will work on using PyTorch here later\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "2b9YhJwtwVpt"
      },
      "id": "2b9YhJwtwVpt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parent_folder = '/content/gdrive/MyDrive/HC18'\n",
        "data_folder = '/content/gdrive/MyDrive/HC18/data'"
      ],
      "metadata": {
        "id": "0EGygYlSwW-j"
      },
      "id": "0EGygYlSwW-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b3a05c7b",
      "metadata": {
        "id": "b3a05c7b"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b856758a",
      "metadata": {
        "id": "b856758a"
      },
      "outputs": [],
      "source": [
        "class HC18(Dataset):\n",
        "    def __init__(self, train = True, transformX = None, transformY = None):\n",
        "        self.pixel_file = pd.read_csv(os.path.join(data_folder, 'training_set_pixel_size_and_HC.csv'))\n",
        "        self.transformX = transformX\n",
        "        self.transformY = transformY\n",
        "        self.train = train\n",
        "        self.train_data, self.validation_data = train_test_split(self.pixel_file, test_size = validation_set_size, random_state = 5)\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.train:\n",
        "            return len(self.train_data)\n",
        "        return len(self.validation_data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.train:\n",
        "            imx_name = os.path.join(data_folder, 'training_set', self.train_data.iloc[index, 0])\n",
        "            imy_name = os.path.join(data_folder, 'training_set', self.train_data.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "        else:\n",
        "            imx_name = os.path.join(data_folder, 'training_set', self.validation_data.iloc[index, 0])\n",
        "            imy_name = os.path.join(data_folder, 'training_set', self.validation_data.iloc[index, 0].replace('.png','_Annotation.png'))\n",
        "        imx = Image.open(imx_name)\n",
        "        imy = Image.open(imy_name).convert('L')\n",
        "        \n",
        "        ## tried some data augmentation techniques\n",
        "        if self.train:\n",
        "          # Random horizontal flipping\n",
        "          if random.random() > 0.5:\n",
        "              imx = TF.hflip(imx)\n",
        "              imy = TF.hflip(imy)\n",
        "\n",
        "          # Random vertical flipping\n",
        "          if random.random() > 0.5:\n",
        "              imx = TF.vflip(imx)\n",
        "              imy = TF.vflip(imy)\n",
        "\n",
        "          # Random rotation\n",
        "          if random.random() > 0.8:\n",
        "            angle = random.choice([-30, -90, -60, -45 -15, 0, 15, 30, 45, 60, 90])\n",
        "            imx = TF.rotate(imx, angle)\n",
        "            imy = TF.rotate(imy, angle)\n",
        "        \n",
        "        # We will use resize, tensorlize, and normalize in the following cell\n",
        "        if self.transformX :\n",
        "            imx = self.transformX(imx)\n",
        "            imy = self.transformY(imy)\n",
        "        \n",
        "        sample = {'image': imx, 'annotation': imy}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d749d6b",
      "metadata": {
        "id": "6d749d6b"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(parent_folder, 'train_data.pickle'), 'rb') as f:\n",
        "    train_data = pickle.load(f)\n",
        "with open(os.path.join(parent_folder, 'validation_data.pickle'), 'rb') as f:\n",
        "    validation_data = pickle.load(f)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = 2)\n",
        "validation_loader = DataLoader(dataset = validation_data, batch_size = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb6fe4b",
      "metadata": {
        "id": "7eb6fe4b"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174a838f",
      "metadata": {
        "id": "174a838f"
      },
      "source": [
        "# Res-U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d77a52",
      "metadata": {
        "id": "56d77a52"
      },
      "outputs": [],
      "source": [
        "class res_conv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, down=True):\n",
        "        super(res_conv, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.ReLU(inplace = True),\n",
        "            )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace = True),\n",
        "            # nn.Dropout(0.5),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.conv2(x1)+x1\n",
        "        return x2\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = res_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            res_conv(in_ch, out_ch),\n",
        "            )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, kernel_size=2, stride=2)\n",
        "        self.conv = res_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diff1 = x2.shape[2]-x1.shape[2]\n",
        "        diff2 = x2.shape[3]-x1.shape[3]\n",
        "        x1 = F.pad(x1, pad=(diff1//2, diff1-diff1//2, diff2//2, diff2-diff2//2))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        # self.conv = nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size=1),\n",
        "        #                          nn.Sigmoid())\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f21c61a",
      "metadata": {
        "id": "0f21c61a"
      },
      "outputs": [],
      "source": [
        "class ResUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(ResUNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "        self.dropout = torch.nn.Dropout2d(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float()\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.dropout(x)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bad1cbcf",
      "metadata": {
        "id": "bad1cbcf",
        "outputId": "5dd3759e-73da-4d5c-e030-a53168e314f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Loaded to GPU\n"
          ]
        }
      ],
      "source": [
        "model = ResUNet(1, 1)\n",
        "model.to('cuda')\n",
        "print(\"Model Loaded to GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0eab9c8",
      "metadata": {
        "id": "d0eab9c8"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75683d5",
      "metadata": {
        "id": "c75683d5"
      },
      "outputs": [],
      "source": [
        "# calculates similarity index between predicted and actual segmentation\n",
        "def dice_index(y_pred, y_actual):\n",
        "    smooth = 0.000001\n",
        "    size_of_batch = y_pred.size(0)\n",
        "    \n",
        "    p1 = y_pred.view(size_of_batch, -1)\n",
        "    p2 = y_actual.view(size_of_batch, -1)\n",
        "    \n",
        "    intersection = (p1 * p2).sum()\n",
        "    \n",
        "    dice =  ((2.0 * intersection )+ smooth) / (p1.sum() + p2.sum() + smooth)\n",
        "    #dice.requires_grad = True\n",
        "    \n",
        "    return dice\n",
        "\n",
        "# calculate dice loss which will be later used in loss function calculation\n",
        "def dice_loss(y_predict, y_train): ## to add in bce looss\n",
        "    return 1 -(dice_index(y_predict, y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only train the model if you want to retrian, screw down to laod the pre-trained model"
      ],
      "metadata": {
        "id": "Kf8lY2Nxwfpc"
      },
      "id": "Kf8lY2Nxwfpc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3526d833",
      "metadata": {
        "scrolled": false,
        "id": "3526d833",
        "outputId": "c83708d3-a5d0-41f6-8a6e-36aa9eb5d0aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  1 Batch:  0 Current Loss:  0.7157742977142334\n",
            "Epoch:  1 Batch:  50 Current Loss:  0.5789473056793213\n",
            "Epoch:  1 Batch:  100 Current Loss:  0.34140944480895996\n",
            "Epoch:  1 Batch:  150 Current Loss:  0.3807904124259949\n",
            "Epoch:  1 Batch:  200 Current Loss:  0.18298697471618652\n",
            "Epoch:  1 Batch:  250 Current Loss:  0.2157599925994873\n",
            "Epoch:  1 Batch:  300 Current Loss:  0.20740929245948792\n",
            "Epoch:  1 Batch:  350 Current Loss:  0.19252453744411469\n",
            "================================================================================\n",
            "Epoch 1 completed\n",
            "Average train loss is 0.3308953294530511: \n",
            "Average validation loss is 0.22743758641183376\n",
            "================================================================================\n",
            "Epoch:  2 Batch:  0 Current Loss:  0.35338571667671204\n",
            "Epoch:  2 Batch:  50 Current Loss:  0.3041520118713379\n",
            "Epoch:  2 Batch:  100 Current Loss:  0.12114259600639343\n",
            "Epoch:  2 Batch:  150 Current Loss:  0.331786185503006\n",
            "Epoch:  2 Batch:  200 Current Loss:  0.09114479273557663\n",
            "Epoch:  2 Batch:  250 Current Loss:  0.19776108860969543\n",
            "Epoch:  2 Batch:  300 Current Loss:  0.1542489230632782\n",
            "Epoch:  2 Batch:  350 Current Loss:  0.1042962595820427\n",
            "================================================================================\n",
            "Epoch 2 completed\n",
            "Average train loss is 0.19945645455271005: \n",
            "Average validation loss is 0.186073428504169\n",
            "================================================================================\n",
            "Epoch:  3 Batch:  0 Current Loss:  0.299995094537735\n",
            "Epoch:  3 Batch:  50 Current Loss:  0.27943694591522217\n",
            "Epoch:  3 Batch:  100 Current Loss:  0.0791703388094902\n",
            "Epoch:  3 Batch:  150 Current Loss:  0.2506301999092102\n",
            "Epoch:  3 Batch:  200 Current Loss:  0.06646538525819778\n",
            "Epoch:  3 Batch:  250 Current Loss:  0.17836624383926392\n",
            "Epoch:  3 Batch:  300 Current Loss:  0.13946597278118134\n",
            "Epoch:  3 Batch:  350 Current Loss:  0.08460499346256256\n",
            "================================================================================\n",
            "Epoch 3 completed\n",
            "Average train loss is 0.1559623649623245: \n",
            "Average validation loss is 0.16754733793437482\n",
            "================================================================================\n",
            "Epoch:  4 Batch:  0 Current Loss:  0.33264589309692383\n",
            "Epoch:  4 Batch:  50 Current Loss:  0.14739885926246643\n",
            "Epoch:  4 Batch:  100 Current Loss:  0.06517016142606735\n",
            "Epoch:  4 Batch:  150 Current Loss:  0.18464267253875732\n",
            "Epoch:  4 Batch:  200 Current Loss:  0.06336206942796707\n",
            "Epoch:  4 Batch:  250 Current Loss:  0.15337377786636353\n",
            "Epoch:  4 Batch:  300 Current Loss:  0.08330915868282318\n",
            "Epoch:  4 Batch:  350 Current Loss:  0.09238111972808838\n",
            "================================================================================\n",
            "Epoch 4 completed\n",
            "Average train loss is 0.13519802105613052: \n",
            "Average validation loss is 0.13963673666119575\n",
            "================================================================================\n",
            "Epoch:  5 Batch:  0 Current Loss:  0.2235771268606186\n",
            "Epoch:  5 Batch:  50 Current Loss:  0.18103492259979248\n",
            "Epoch:  5 Batch:  100 Current Loss:  0.051205188035964966\n",
            "Epoch:  5 Batch:  150 Current Loss:  0.3165391981601715\n",
            "Epoch:  5 Batch:  200 Current Loss:  0.09384095668792725\n",
            "Epoch:  5 Batch:  250 Current Loss:  0.14694982767105103\n",
            "Epoch:  5 Batch:  300 Current Loss:  0.05604971945285797\n",
            "Epoch:  5 Batch:  350 Current Loss:  0.06560865789651871\n",
            "================================================================================\n",
            "Epoch 5 completed\n",
            "Average train loss is 0.11747080013155937: \n",
            "Average validation loss is 0.1605810993537307\n",
            "================================================================================\n",
            "Epoch:  6 Batch:  0 Current Loss:  0.2219650149345398\n",
            "Epoch:  6 Batch:  50 Current Loss:  0.13625028729438782\n",
            "Epoch:  6 Batch:  100 Current Loss:  0.050887320190668106\n",
            "Epoch:  6 Batch:  150 Current Loss:  0.10203705728054047\n",
            "Epoch:  6 Batch:  200 Current Loss:  0.09013566374778748\n",
            "Epoch:  6 Batch:  250 Current Loss:  0.14337566494941711\n",
            "Epoch:  6 Batch:  300 Current Loss:  0.1609557867050171\n",
            "Epoch:  6 Batch:  350 Current Loss:  0.09427714347839355\n",
            "================================================================================\n",
            "Epoch 6 completed\n",
            "Average train loss is 0.11317059145309032: \n",
            "Average validation loss is 0.11247465651482344\n",
            "================================================================================\n",
            "Epoch:  7 Batch:  0 Current Loss:  0.17704004049301147\n",
            "Epoch:  7 Batch:  50 Current Loss:  0.12108078598976135\n",
            "Epoch:  7 Batch:  100 Current Loss:  0.04732707887887955\n",
            "Epoch:  7 Batch:  150 Current Loss:  0.14337192475795746\n",
            "Epoch:  7 Batch:  200 Current Loss:  0.05208935588598251\n",
            "Epoch:  7 Batch:  250 Current Loss:  0.11843831092119217\n",
            "Epoch:  7 Batch:  300 Current Loss:  0.09846954792737961\n",
            "Epoch:  7 Batch:  350 Current Loss:  0.0563039667904377\n",
            "================================================================================\n",
            "Epoch 7 completed\n",
            "Average train loss is 0.10207268471829593: \n",
            "Average validation loss is 0.08708901792764663\n",
            "================================================================================\n",
            "Epoch:  8 Batch:  0 Current Loss:  0.1706348955631256\n",
            "Epoch:  8 Batch:  50 Current Loss:  0.12388823926448822\n",
            "Epoch:  8 Batch:  100 Current Loss:  0.04605276137590408\n",
            "Epoch:  8 Batch:  150 Current Loss:  0.23614159226417542\n",
            "Epoch:  8 Batch:  200 Current Loss:  0.05441321060061455\n",
            "Epoch:  8 Batch:  250 Current Loss:  0.13325631618499756\n",
            "Epoch:  8 Batch:  300 Current Loss:  0.07623071223497391\n",
            "Epoch:  8 Batch:  350 Current Loss:  0.059306517243385315\n",
            "================================================================================\n",
            "Epoch 8 completed\n",
            "Average train loss is 0.09272657149471343: \n",
            "Average validation loss is 0.16792091593146324\n",
            "================================================================================\n",
            "Epoch:  9 Batch:  0 Current Loss:  0.23824578523635864\n",
            "Epoch:  9 Batch:  50 Current Loss:  0.11894838511943817\n",
            "Epoch:  9 Batch:  100 Current Loss:  0.03883742541074753\n",
            "Epoch:  9 Batch:  150 Current Loss:  0.14997431635856628\n",
            "Epoch:  9 Batch:  200 Current Loss:  0.05798827111721039\n",
            "Epoch:  9 Batch:  250 Current Loss:  0.08226047456264496\n",
            "Epoch:  9 Batch:  300 Current Loss:  0.05608954280614853\n",
            "Epoch:  9 Batch:  350 Current Loss:  0.05989140272140503\n",
            "================================================================================\n",
            "Epoch 9 completed\n",
            "Average train loss is 0.08959348502568901: \n",
            "Average validation loss is 0.14384377744048835\n",
            "================================================================================\n",
            "Epoch:  10 Batch:  0 Current Loss:  0.13776835799217224\n",
            "Epoch:  10 Batch:  50 Current Loss:  0.11999425292015076\n",
            "Epoch:  10 Batch:  100 Current Loss:  0.036764804273843765\n",
            "Epoch:  10 Batch:  150 Current Loss:  0.11446018517017365\n",
            "Epoch:  10 Batch:  200 Current Loss:  0.043653056025505066\n",
            "Epoch:  10 Batch:  250 Current Loss:  0.11725465953350067\n",
            "Epoch:  10 Batch:  300 Current Loss:  0.04649767279624939\n",
            "Epoch:  10 Batch:  350 Current Loss:  0.06250414252281189\n",
            "================================================================================\n",
            "Epoch 10 completed\n",
            "Average train loss is 0.08615068729035556: \n",
            "Average validation loss is 0.1556755429133773\n",
            "================================================================================\n",
            "Epoch:  11 Batch:  0 Current Loss:  0.10308023542165756\n",
            "Epoch:  11 Batch:  50 Current Loss:  0.10555407404899597\n",
            "Epoch:  11 Batch:  100 Current Loss:  0.037491925060749054\n",
            "Epoch:  11 Batch:  150 Current Loss:  0.21749535202980042\n",
            "Epoch:  11 Batch:  200 Current Loss:  0.04780514910817146\n",
            "Epoch:  11 Batch:  250 Current Loss:  0.09431334584951401\n",
            "Epoch:  11 Batch:  300 Current Loss:  0.05335506424307823\n",
            "Epoch:  11 Batch:  350 Current Loss:  0.058134134858846664\n",
            "================================================================================\n",
            "Epoch 11 completed\n",
            "Average train loss is 0.08620736715383828: \n",
            "Average validation loss is 0.09186218185350299\n",
            "================================================================================\n",
            "Epoch:  12 Batch:  0 Current Loss:  0.15655148029327393\n",
            "Epoch:  12 Batch:  50 Current Loss:  0.12499125301837921\n",
            "Epoch:  12 Batch:  100 Current Loss:  0.03497621417045593\n",
            "Epoch:  12 Batch:  150 Current Loss:  0.11839038133621216\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  12 Batch:  200 Current Loss:  0.06176935136318207\n",
            "Epoch:  12 Batch:  250 Current Loss:  0.08784111589193344\n",
            "Epoch:  12 Batch:  300 Current Loss:  0.04227422550320625\n",
            "Epoch:  12 Batch:  350 Current Loss:  0.07076704502105713\n",
            "================================================================================\n",
            "Epoch 12 completed\n",
            "Average train loss is 0.08058109126519412: \n",
            "Average validation loss is 0.0954960647597909\n",
            "================================================================================\n",
            "Epoch:  13 Batch:  0 Current Loss:  0.12022527307271957\n",
            "Epoch:  13 Batch:  50 Current Loss:  0.1989845484495163\n",
            "Epoch:  13 Batch:  100 Current Loss:  0.029786601662635803\n",
            "Epoch:  13 Batch:  150 Current Loss:  0.16875694692134857\n",
            "Epoch:  13 Batch:  200 Current Loss:  0.0406184047460556\n",
            "Epoch:  13 Batch:  250 Current Loss:  0.07169608026742935\n",
            "Epoch:  13 Batch:  300 Current Loss:  0.05640142410993576\n",
            "Epoch:  13 Batch:  350 Current Loss:  0.04861804097890854\n",
            "================================================================================\n",
            "Epoch 13 completed\n",
            "Average train loss is 0.07841781796887518: \n",
            "Average validation loss is 0.09562352068722248\n",
            "================================================================================\n",
            "Epoch:  14 Batch:  0 Current Loss:  0.13393191993236542\n",
            "Epoch:  14 Batch:  50 Current Loss:  0.08223386108875275\n",
            "Epoch:  14 Batch:  100 Current Loss:  0.04131980985403061\n",
            "Epoch:  14 Batch:  150 Current Loss:  0.11920776963233948\n",
            "Epoch:  14 Batch:  200 Current Loss:  0.046929772943258286\n",
            "Epoch:  14 Batch:  250 Current Loss:  0.09208690375089645\n",
            "Epoch:  14 Batch:  300 Current Loss:  0.11506703495979309\n",
            "Epoch:  14 Batch:  350 Current Loss:  0.07323233783245087\n",
            "================================================================================\n",
            "Epoch 14 completed\n",
            "Average train loss is 0.07910278233699501: \n",
            "Average validation loss is 0.09597943745553493\n",
            "================================================================================\n",
            "Epoch:  15 Batch:  0 Current Loss:  0.12129843235015869\n",
            "Epoch:  15 Batch:  50 Current Loss:  0.06991586089134216\n",
            "Epoch:  15 Batch:  100 Current Loss:  0.038591813296079636\n",
            "Epoch:  15 Batch:  150 Current Loss:  0.2620851695537567\n",
            "Epoch:  15 Batch:  200 Current Loss:  0.04259464144706726\n",
            "Epoch:  15 Batch:  250 Current Loss:  0.08156464993953705\n",
            "Epoch:  15 Batch:  300 Current Loss:  0.07337737083435059\n",
            "Epoch:  15 Batch:  350 Current Loss:  0.07673554867506027\n",
            "================================================================================\n",
            "Epoch 15 completed\n",
            "Average train loss is 0.07340315269771963: \n",
            "Average validation loss is 0.1032023530267179\n",
            "================================================================================\n",
            "Epoch:  16 Batch:  0 Current Loss:  0.16470052301883698\n",
            "Epoch:  16 Batch:  50 Current Loss:  0.055975139141082764\n",
            "Epoch:  16 Batch:  100 Current Loss:  0.04561777412891388\n",
            "Epoch:  16 Batch:  150 Current Loss:  0.06258329749107361\n",
            "Epoch:  16 Batch:  200 Current Loss:  0.04075320065021515\n",
            "Epoch:  16 Batch:  250 Current Loss:  0.08789969980716705\n",
            "Epoch:  16 Batch:  300 Current Loss:  0.0390990749001503\n",
            "Epoch:  16 Batch:  350 Current Loss:  0.05447273701429367\n",
            "================================================================================\n",
            "Epoch 16 completed\n",
            "Average train loss is 0.07230686345603317: \n",
            "Average validation loss is 0.14893912283703684\n",
            "================================================================================\n",
            "Epoch:  17 Batch:  0 Current Loss:  0.12101612985134125\n",
            "Epoch:  17 Batch:  50 Current Loss:  0.0839359313249588\n",
            "Epoch:  17 Batch:  100 Current Loss:  0.035358086228370667\n",
            "Epoch:  17 Batch:  150 Current Loss:  0.08192343264818192\n",
            "Epoch:  17 Batch:  200 Current Loss:  0.046592436730861664\n",
            "Epoch:  17 Batch:  250 Current Loss:  0.09231667220592499\n",
            "Epoch:  17 Batch:  300 Current Loss:  0.06100379675626755\n",
            "Epoch:  17 Batch:  350 Current Loss:  0.09865683317184448\n",
            "================================================================================\n",
            "Epoch 17 completed\n",
            "Average train loss is 0.06957643020898104: \n",
            "Average validation loss is 0.07865183718502522\n",
            "================================================================================\n",
            "Epoch:  18 Batch:  0 Current Loss:  0.06578169018030167\n",
            "Epoch:  18 Batch:  50 Current Loss:  0.08934545516967773\n",
            "Epoch:  18 Batch:  100 Current Loss:  0.03440020978450775\n",
            "Epoch:  18 Batch:  150 Current Loss:  0.11240120232105255\n",
            "Epoch:  18 Batch:  200 Current Loss:  0.03820597007870674\n",
            "Epoch:  18 Batch:  250 Current Loss:  0.07939232885837555\n",
            "Epoch:  18 Batch:  300 Current Loss:  0.054624248296022415\n",
            "Epoch:  18 Batch:  350 Current Loss:  0.05906602740287781\n",
            "================================================================================\n",
            "Epoch 18 completed\n",
            "Average train loss is 0.0684926100820303: \n",
            "Average validation loss is 0.08352516071870923\n",
            "================================================================================\n",
            "Epoch:  19 Batch:  0 Current Loss:  0.06359782814979553\n",
            "Epoch:  19 Batch:  50 Current Loss:  0.09738970547914505\n",
            "Epoch:  19 Batch:  100 Current Loss:  0.028688129037618637\n",
            "Epoch:  19 Batch:  150 Current Loss:  0.06875177472829819\n",
            "Epoch:  19 Batch:  200 Current Loss:  0.035229235887527466\n",
            "Epoch:  19 Batch:  250 Current Loss:  0.09547706693410873\n",
            "Epoch:  19 Batch:  300 Current Loss:  0.04483726993203163\n",
            "Epoch:  19 Batch:  350 Current Loss:  0.05656520277261734\n",
            "================================================================================\n",
            "Epoch 19 completed\n",
            "Average train loss is 0.06832219635136426: \n",
            "Average validation loss is 0.13654786525294185\n",
            "================================================================================\n",
            "Epoch:  20 Batch:  0 Current Loss:  0.08383260667324066\n",
            "Epoch:  20 Batch:  50 Current Loss:  0.05120643228292465\n",
            "Epoch:  20 Batch:  100 Current Loss:  0.02879704162478447\n",
            "Epoch:  20 Batch:  150 Current Loss:  0.09237570315599442\n",
            "Epoch:  20 Batch:  200 Current Loss:  0.03744101524353027\n",
            "Epoch:  20 Batch:  250 Current Loss:  0.08700177818536758\n",
            "Epoch:  20 Batch:  300 Current Loss:  0.0422506183385849\n",
            "Epoch:  20 Batch:  350 Current Loss:  0.04886763542890549\n",
            "================================================================================\n",
            "Epoch 20 completed\n",
            "Average train loss is 0.06330195615999401: \n",
            "Average validation loss is 0.07456391299143433\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "epochs = 20 \n",
        "\n",
        "train_running_loss_history = []\n",
        "validation_running_loss_history =[]\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_running_loss = 0.0\n",
        "    validation_running_loss = 0.0  \n",
        "    model.train()\n",
        "    for ith_batch, sample_batched in enumerate(train_loader):\n",
        "        X_train = sample_batched['image'].cuda()\n",
        "        y_train = sample_batched['annotation'].to(\"cuda:0\")\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train)\n",
        "        loss = 0.30 * dice_loss(y_pred, y_train) +  0.70 * criterion(y_pred, y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ith_batch % 50 == 0:\n",
        "            print('Epoch: ', e + 1, 'Batch: ', ith_batch, 'Current Loss: ', loss.item())\n",
        "        train_running_loss += loss.item()\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for ith_batch, sample_batched in enumerate(validation_loader):\n",
        "                X_val = sample_batched['image'].cuda()\n",
        "                y_val = sample_batched['annotation'].to(\"cuda:0\")\n",
        "                y_out = model(X_val)\n",
        "                out_val = (y_out + 0.5).int().float()\n",
        "                val_loss = 0.3 * dice_loss(out_val, y_val)  + 0.7 * criterion(y_out, y_val)\n",
        "                validation_running_loss += val_loss.item()\n",
        "            print(\"================================================================================\")\n",
        "            print(\"Epoch {} completed\".format(e + 1))\n",
        "\n",
        "            train_epoch_loss = train_running_loss / len(train_loader)\n",
        "            validation_epoch_loss = validation_running_loss / len(validation_loader)\n",
        "\n",
        "            print(\"Average train loss is {}: \".format(train_epoch_loss))\n",
        "            print(\"Average validation loss is {}\".format(validation_epoch_loss))\n",
        "            print(\"================================================================================\")\n",
        "            train_running_loss_history.append(train_epoch_loss)\n",
        "            validation_running_loss_history.append(validation_epoch_loss)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e50f178",
      "metadata": {
        "id": "5e50f178",
        "outputId": "c81791de-79e0-4e51-f17f-d700a29e7c9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x15541f8a1ca0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_running_loss_history, label = 'Train Loss')\n",
        "plt.plot(validation_running_loss_history, label = 'Validation Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf76e565",
      "metadata": {
        "id": "bf76e565",
        "outputId": "1eff0deb-2459-4de7-873b-c9d8ca94b871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 572, 572])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "X_train.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da109f2",
      "metadata": {
        "id": "7da109f2"
      },
      "outputs": [],
      "source": [
        "torch.save(model, os.path.join(parent_folder, 'savedmodel/ResUNet.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can load a model instead"
      ],
      "metadata": {
        "id": "8SwFlBRdwrRn"
      },
      "id": "8SwFlBRdwrRn"
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(os.path.join(parent_folder, 'savedmodel/ResUNet.pt'))\n",
        "model.to('cuda')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "v0HzP1xlwlbL"
      },
      "id": "v0HzP1xlwlbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe50d1b",
      "metadata": {
        "id": "abe50d1b"
      },
      "outputs": [],
      "source": [
        "def avg_dice_index(dataloader):\n",
        "    dice = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for ith_batch, sample_batched in enumerate(dataloader):\n",
        "            X_train = sample_batched['image'].to('cuda')\n",
        "            y_train = sample_batched['annotation'].to('cuda')\n",
        "            y_predict = (model(X_train) + 0.5).int().float()\n",
        "            dice += dice_index(y_predict, y_train)\n",
        "    avg_dice = dice / len(dataloader)\n",
        "    return avg_dice.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4558cda4",
      "metadata": {
        "id": "4558cda4",
        "outputId": "64a46776-4009-40ee-ca55-2a53c125d441"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9472250938415527"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_dice_index(validation_loader)    #### Dice index of validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "175c35d2",
      "metadata": {
        "id": "175c35d2",
        "outputId": "6b90a7ec-6175-4272-a040-3a9f5782e22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9432870745658875"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "avg_dice_index(train_loader)    #### Dice index of validation data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}